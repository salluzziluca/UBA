 Entrenar un modelo es un problema de optimizacion. Buscamos los param optimos para minimizar o maximizar la metrica elegida. Una vez entranado, el modelo queda definido por sus parametros.

Los ==hiperparametros== son aquellos que parametrizan el entrenamiento de nuestro modelo
![[Pasted image 20231012162034.png]]

Hay que buscar los mejores hiper-parametros (tuning)

## Tuning
### Grid-search
Establecemos un conjunto de valores a probar por cada hiper-parámetro
probamos cada combinacion de hipers y nos quedamos con la mejor. Una vez que encontramos los valores optimos podemos refinar la busqueda (si el optimo está en un extremo, por ejemplo, o asi está entre dos valores)

#### Random search
tomamos un conjunto de valores igual que en grid, probamos k combinaciones aleatorias y nos quedamos con la mejor (decidimos cuanto tiempo invertir pero no pro)

### Búsqueda Bayesiana

definimos una dist de proba y rangos por cada hiper-parametro. El algoritmo va probando combinaciones de hiper parametros de forma bayesiana
![[Pasted image 20231012163221.png]]

## Kfold cross valitadion
Como no podemos usar el set de test para entrenar al modelo, tenemos que partir al set de entrenamiento en 2: Train y Validation. Para esto partimos el set de entrenamiento en k particiones, tomando 1 fold como validacion y el resto como train, luego vamos rotando
![[Pasted image 20231012164010.png]]