Aplicacion de la esperanza y la varianza a [[2.4 Vectores Aleatorios]]
## Propiedades de Orden
Sea $\mathbb{X}$ un vector aleatorio y $g: -> \mathbb{R}^k\to \mathbb{R}$ una funcion tenemos que: 
1. Si $\mathbb{X}>0$ entonces $E(\mathbb{X})>0$
2. Si $g(\mathbb{X}>0)$ entonces $E(g(X))>0$
3. Sea $h(\mathbb{X})>g(\mathbb{X})$entonces $E(h(\mathbb{X}))>E(g(\mathbb{X}))$
4. $E(|\mathbb{X}|)\geq E(\mathbb{X}$
5. $E(|\mathbb{X}\mathbb{Y}|)\leq \sqrt{ E(\mathbb{X}^2)E(\mathbb{Y}^2) }$ 

## Mas propiedades
1. $E\left[ \sum^{n}_{i=1} a_{i} \mathbb{X}_{i}\right]=\sum^{n}_{i=1}a_{i}E(\mathbb{X}_{i})$
2. Si $X_1,\dots,X_{n}$ son independientes entonces $E(\Pi^n_{i=1}X_{i})=\Pi^n_{i=1}E(X_{i})$. La esperanza del producto es el producto de las esperanzas (si las var son independientes)
# Covarianza
Sean X e Y dos VA
$Cov(X, Y) = E[(X-E(X))(Y-E(Y))] = E(X.Y)-E(X)E(Y)$
Nos importa el signo de la covarianza, que nos muestra el grado de relacion lineal entre dos variables

## propiedades
1. $cov(X, Y)= E(X.Y)-E(X)E(Y)$
2. Si X e Y son independientes entonces E(XY)=E(X)E(Y) y, por lo tanto la Cov(X, Y)=0
3. $Cov(a+bX, c+dY)=b.d.cov(X,Y)$
4. $Cov(X+Y, Z)= Cov(X, Z)+Cov(Y, Z)$
5. $var(X+Y)=var(X)+var(Y)+2cov(X, Y)$
6. Recta de regresión $\hat{y}=\frac{cov(x,y)}{var(x)}(X-{E[X]})+E[Y]$ con $\frac{cov(x,y)}{var(x)}$ pendiente de la recta
6.  Recta de Regresión de Y basada en x $g(x)= \hat{y}=\frac{cov(x,y)}{var(x)}(x-E(x))+E(y)$

>>>>>>> origin/main

# Coeficiente de Correlación
$$\rho_{XY}=\frac{Cov(X, Y)}{\sqrt{ Var(X)Var(Y) }}$$
## propiedades
si el coef de correlacion da 1, quiere decir que la funcion sea una Y= mX+b