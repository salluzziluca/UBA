---
dg-publish: true
---
> La VA X que toma todos los valores reales $-\infty<x<\infty$ tiene una distribución normal de parámetros $\mu \in R$ y $\sigma^2>0$ si su función de densidad es de la forma $$f_{X}(x)=\frac{1}{\sqrt{ 2\pi \sigma² }}.e^{-\frac{1}{2\sigma^2}(x-\mu)²}$$
> Notacion: $X ~ N(\mu, \sigma^2)$

![[Pasted image 20231026173410.png]]
$E[X]=\mu$
$var(X)=\sigma^2$
## Estandarizacion
Estandarizar es aplicar la siguiente transformacion para calcular cualquier proba para $X \sim N(\mu, \sigma^2)$
$$P(X \leq x )= P\left( Z \leq \frac{{x-\mu}}{\sigma} \right)= \phi\left( \frac{{x-\mu}}{\sigma} \right)$$ Luego busco eso en la tabla y listop
![[Pasted image 20231026174631.png]]

# Distribución Normal Multivariada

Se dice que el vector aleatorio $X=(X_1, ..., X_p)$. Tiene dist multivariada de dimension p, de parametros $\mu \in \mathbb{R}^p$ y $\Upsigma \in \mathbb{R}^{pxp}$ (simetrica y definida positiva) $X$ ~ $N_{p}(\mu, \Upsigma)$ si su función de densidad está dada por $$f_{X}(x)= \frac{1}{(2\pi)^{p/2}|\Upsigma|^{1/2}}.\exp\{-\frac{1}{2}(x-\mu)^T.\Upsigma^{-1}(x-\mu)\}$$X y x son vectores de R^p
 ![[Pasted image 20231026175126.png]]

#### propiedades
1. Combinacion de varibles aleatorias independientes es una $N(\mu, \sigma)$
1. Si X ~ $N_p(0, diag(\lambda_1, ..., \lambda_p))$ entonces X_1, ..., X_p son independientes y $X_i$ ~ $N(0, \lambda_i)$ Esto quiere decir que en el caso de las normales, covarianza 0 implica independencia
2. Si X ~ $N_{p}(\mu, \Sigma)$ y $A \in R^{pxp}$ no singular entonces Ax+b ~ $N_{p}(A \mu +b, A \Upsigma A^T)$ 

![[Pasted image 20231026175740.png]]

### Teorema:
sean $X_{1}, \dots, X_{n}$ VA independientes con $X_{i}$~$N(\mu_{i}), \sigma^2_{i}, i = 1, \dots, n$ y sea $y=\Upsigma^n_{i=1}a_{i}X_{i}$. Entonces Y tendrá distribución normal de parámetros $\mu_{Y}=\sum^{n}_{i=1}a_{i}\mu_{i}$ y $\sigma^2_{y}=\sum^{n}_{i=1}a^2_{i}\sigma^2_{i}$

# Teoremas Límites
## Ley de los grandes números
Si se tiene una sucesion de VA (X_n)n>= 1 independientes con $E[X_i]=\mu < \infty \ y\ var(X_{i)})=\sigma^2<\infty$, $\bar{X}=\frac{1}{n}s\sum^{n}_{i=1}X_{i}$ entonces 
$$\bar{X}\to \mu$$
#### ley debil de los grandes numeros (usando markov)
$$P(|\bar{X}_{n}-\mu|>\varepsilon)\to{0}$$ cuando n->$\infty$
$E(\bar{X}= \mu), \ var(\bar{X}_{n})=\frac{\sigma²}{n}$


## Teorema Central del Límite
Sean $(X_{n})_{n\geq 1}$ una sucesion de VA indep e identicamente distribuidas con $E(X_{i})=\mu<\infty$ y $var(X_i)=\sigma^2$, $i=1,\dots, n$, entonces (bajo ciertas condiciones generales)
sucesion
$$P(\frac{ \sum^{n}_{i=1}x_{i}-n.\mu}{\sqrt{ n.\sigma^2 } }\leq \frac{t-n \mu}{\sqrt{ n. \sigma^2 }}) \to \phi(\frac{t-n\mu}{\sqrt{ n \sigma^2 }})$$
![[ayudaaaa.png]]
Para que valor de n podemos usar la aproximacion?
Depdende de la dist original, con iniformes alcanza con 4, con otras muy asimetricas por ahi necesito 80, siempre hay que entender que es una aproximacion


![[Pasted image 20231210171656.png]]![[Pasted image 20231210171713.png]]
![[Pasted image 20231210171717.png]]