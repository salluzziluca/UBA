Metodo para construir estimadores puntuales. Se basan que en los experimentos aleatorios los resultados deben alta proba de ocurrir 

>  Diremos que $\hat{\theta}(\underline{X} )$ es un estimador de máximo Verosimilitud de $\theta$ si se cumple que $$f_{\hat{\theta}}(\underline{X})=\max_{\theta} f_{\theta}(\underline{x})$$
>  El valor que maximice la proba conjunta evaluada en la muestra observada. Es decir, que maximice la [[9.1 Introducción a la Estadística#Funcion de Verosimilitud|funcion de verosimilitud]]

Entonces: Busco el theta que maximice L(theta) y despues calculo $\hat{\Theta}=\hat{\Theta}(\underline{X})$

![[Pasted image 20231109172447.png]]


# Principio de invarianza. 
si $\lambda=q(\theta)$ es una funcion biunivoca de $\theta$. Y $\hat{\theta}$ es el Estimador de Maxima Verosimilitud de $\theta$, entonces $\hat{\lambda}=q(\hat{\theta})$será el EMV de $\lambda$


# Bondad de los Estimadores
Dada $X_{1}, \dots, X_{n} \sim^{idd} F_{\theta}(x), \ \theta \in \Theta$ una muestra aleatoria. Estimamos $\theta$ por $\hat{\theta}$. El riesgo de la estimacion se mide como el![[3.4 Predicciones#error cuadratico medio]] con parametros $\theta$, $\hat{\theta}$
Un estiamador optimo será $\hat{\Theta}^*$ tal que 