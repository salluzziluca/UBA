# ‚úÖ Pasos para obtener estimadores por m√°xima verosimilitud (MLE)

## 1. Defin√≠ la funci√≥n de densidad o probabilidad

Sea $f_\theta(x)$ la densidad (para variables continuas) o funci√≥n de probabilidad (para discretas), donde $\theta$ es el par√°metro o conjunto de par√°metros a estimar.

**Ejemplo (Weibull con $k = 2$):**

$$
f_\alpha(x) = \frac{2x}{\alpha^2} e^{-(x/\alpha)^2}
$$

---

## 2. Escrib√≠ la funci√≥n de verosimilitud $L(\theta)$

Para una muestra i.i.d. $x_1, x_2, \ldots, x_n$, la verosimilitud es:

$$
L(\theta) = \prod_{i=1}^n f_\theta(x_i)
$$

---

## 3. Calcul√° el logaritmo de la verosimilitud $\log L(\theta)$

Transformamos la verosimilitud para facilitar el c√°lculo:

$$
\log L(\theta) = \sum_{i=1}^n \log f_\theta(x_i)
$$

---

## 4. Deriv√° respecto del par√°metro $\theta$

Calculamos:

$$
\frac{d}{d\theta} \log L(\theta)
$$

Esto se llama **ecuaci√≥n de verosimilitud**.

---

## 5. Igual√° la derivada a cero y resolv√© para $\theta$

$$
\frac{d}{d\theta} \log L(\theta) = 0 \quad \Rightarrow \quad \hat{\theta}
$$

Eso te da el **estimador m√°ximo veros√≠mil**.

---

## 6. Verific√° que sea un m√°ximo (opcional pero recomendable)

Pod√©s:

- Verificar que la segunda derivada sea negativa:
  $$
  \frac{d^2}{d\theta^2} \log L(\theta) < 0
  $$

- Ver que $\log L(\theta)$ tenga forma de m√°ximo (c√≥ncava).

---

## ‚ú≥Ô∏è Ejemplo aplicado: Weibull(2, $\alpha$)

1. Densidad:
   $$
   f_\alpha(x) = \frac{2x}{\alpha^2} e^{-(x/\alpha)^2}
   $$

2. Verosimilitud:
   $$
   L(\alpha) = \prod_{i=1}^n \frac{2x_i}{\alpha^2} e^{-(x_i/\alpha)^2}
   $$

3. Log-verosimilitud:
   $$
   \log L(\alpha) = C - 2n \log \alpha - \sum_{i=1}^n \left(\frac{x_i^2}{\alpha^2} \right)
   $$

4. Derivada:
   $$
   \frac{d}{d\alpha} \log L(\alpha) = -\frac{2n}{\alpha} + \frac{2}{\alpha^3} \sum x_i^2
   $$

5. Igualamos a cero y despejamos:
   $$
   \hat{\alpha} = \sqrt{\frac{1}{n} \sum x_i^2}
   $$

---

## üîÅ Este procedimiento es general

Sirve tambi√©n para:

- Normal ($\mu$, $\sigma^2$)
- Exponencial ($\lambda$)
- Bernoulli ($p$)
- Binomial ($p$, con $n$ conocido)
- Poisson ($\lambda$)
- Uniforme
- Pareto, Gamma, etc.
